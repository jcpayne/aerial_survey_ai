{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes the workflow for pre-preparation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image types and naming conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flight session format is as follows, e.g. for TA25-RKE-20191201A:\n",
    "* TA25 = survey code (4 chars, holdover from DOS days when there were 4-char survey codes and 4-char data table codes)\n",
    "* RKE = aircraft callsign (unique per survey);\n",
    "* 20191201 = YYYYMMDD\n",
    "* A = first session flown of that day. Sometimes there’s a B, and it’s possible there could be higher letters but that’s never happened yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of UUIDs and database for image security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing of images to convert .NEF to .jpg and adjust contrast, resolution, size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migrating files from AWS to Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had a lot of data on an Amazon AWS virtual machine (VM) that we wanted to transfer to a Microsoft Azure VM. The Azure migration tools assume that you are going to want the data in a 'file store', but file store access is generally too slow for machine learning and we wanted to put the data on a solid-state hard drive (SSD) that was attached to our Azure VM.  AWS access control is complex, and can make getting data difficult.  We found the easiest method was:\n",
    "1. install the AWS CLI (command-line interface program) on our Azure machine;\n",
    "2. Set up an AWS profile on the Azure VM that we wanted to pull the data into, and\n",
    "3. Use the AWS CLI on the Azure VM to pull the data from AWS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps (see https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html for installation):\n",
    "```bash\n",
    "#Install the AWS CLI on an Azure Linux VM \n",
    "ssh <my_server>\n",
    "curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "unzip awscliv2.zip\n",
    "sudo ./aws/install\n",
    "\n",
    "#Set up AWS profile on Azure VM (get the Access Key & Secret Access Key from your AWS account first)\n",
    "aws configure --profile <profile_name>\n",
    "    AWS Access Key ID [None]: <from AWS>\n",
    "    AWS Secret Access Key [None]: <from AWS>\n",
    "    Default region name [None]: <AWS bucket region, e.g., us-west-2>\n",
    "    Default output format [None]:\n",
    "\n",
    "#Sync folders, using the profile (run this on the Azure VM)\n",
    "cd <project_data_root_folder>\n",
    "aws s3 --profile <profile_name> sync s3://<bucket>/<directory>/ .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
