# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_detectron2_utilities.ipynb (unless otherwise specified).

__all__ = ['register_dataset_from_file', 'register_dataset_from_dicts', 'create_detectron2_dicts', 'evaluate_dicts',
           'evaluate_dataloader_item', 'dummy_detectron2_result', 'combine_tile_annotations', 'save_annotated_image',
           'save_annotated_images', 'write_results_to_xml', 'read_in_predictions']

# Cell
import os
from pathlib import Path
import torch
import torch.nn.functional as F
import numpy as np
import pandas as pd
from collections import Counter
from collections import OrderedDict #tile_results is an OrderedDict

#These are for PascalVOCWriter and PascalVOCReader
import sys
from xml.etree import ElementTree
from xml.etree.ElementTree import Element, SubElement
#import xml.etree.ElementTree as etree
from lxml import etree
import codecs

import detectron2
from fvcore.common.file_io import PathManager
from detectron2.evaluation import inference_context
from detectron2.utils.visualizer import Visualizer
from detectron2.structures import Instances, Boxes, BoxMode
from detectron2.data import DatasetCatalog, MetadataCatalog
from .dataprep import *

# Cell
def register_dataset_from_file(imagedir,anndir,textfile,shuffle, dsetname, CLASS_NAMES,rename_classes, omit_classes):
    """Registers a dataset with Detectron2 by creating a list of dicts from files (see create_detectron2_dicts).
    Parameters:
        imagedir: pathlib Path.  Directory of images
        anndir: pathlib Path.  Directory of Pascal-VOC-style XML annotation files (one per image).
        textfile: a .txt file containing a list (one per row) of filenames without path or extension.
        shuffle: Boolean.  If True, will shuffle the indices (should only be done for training data.)
        dsetname: string.  The name of the dataset
        CLASS_NAMES: list of strings.  The set of classnames for the model.
        rename_classes: dict of class names to rename, in the form {oldname: newname}.
        omit_classes: list of class names to omit (those instances are skipped).
    """
    ##Pop the dataset name from the _REGISTERED dict if it already exists
    if dsetname in DatasetCatalog.list():
        DatasetCatalog.remove(dsetname)

    DatasetCatalog.register(dsetname, lambda imagedir=imagedir : create_detectron2_dicts(imagedir,anndir,textfile, CLASS_NAMES, rename_classes, omit_classes, shuffle=False))
    MetadataCatalog.get(dsetname).set(thing_classes=CLASS_NAMES)
#    survey_metadata = MetadataCatalog.get("survey_train")

# Cell
def register_dataset_from_dicts(ddicts,dsetname,CLASS_NAMES):
    """Registers a dataset with Detectron2, using a list of dicts as the source.
    Parameters:
        ddicts: list containing dicts (one per file) of object annotations in Detectron2 format
        dsetname: string.  The name of the dataset
        CLASS_NAMES: list of strings.  The set of classnames for the model.
    """
    #Pop the dataset name from the _REGISTERED dict if it already exists
    if dsetname in DatasetCatalog.list():
        DatasetCatalog._REGISTERED.pop(dsetname)
    #Register a name with a function to retrieve the dataset
    DatasetCatalog.register(dsetname, lambda dsetname=dsetname: ddict)
    MetadataCatalog.get(dsetname).set(thing_classes=CLASS_NAMES)

# Cell
def create_detectron2_dicts(imagedir,anndir,textfile, CLASS_NAMES, rename_classes, omit_classes, shuffle=False):
    """Creates a set of Detectron2-style dicts of object annotations from pairs of
    image and annotation files.  Filters class names to omit instances from some classes
    and/or rename other classes, depending on the 'rename_classes' and 'omit_classes' arguments.
    Parameters:
       imagedir: pathlib Path.  Directory of images
       anndir: pathlib Path.  Directory of Pascal-VOC-style XML annotation files (one per image).
       textfile: string.  Full path for a .txt file containing a list (one per row) of filenames
                             without path or extension.
       CLASS_NAMES: list of strings.  The set of classnames for the model.
       rename_classes: dict of class names to rename, in the form {oldname: newname}.
       omit_classes: list of class names to omit (those instances are skipped).
       shuffle: Boolean.  If True, will shuffle the indices (should only be done for training data.)
    Note: imagedir and anndir are expected to contain files with names that match, except for
       the extension (.jpg, .xml)
    Returns a list of dicts (one per file) containing all of the objects in each file.
    Any object whose class is neither omitted nor in CLASS_NAMES is assigned the label "other_animal".
    """
    #Open the train.txt or valid.txt files
    with open(textfile) as f:
        fileids = np.loadtxt(f, dtype=np.str)

    #Randomly shuffle the order of the training files on each run (leave validation file order unchanged)
    if (shuffle==True):
        random.shuffle(fileids)

    dicts = []
    #Note: fileid is the filename stem (no path or suffix) from train.txt or valid.txt.
    #anno_file and jpeg_file just join that stem to a root directory and give it a suffix.
    for fileid in fileids:
        anno_file = str(Path(anndir/fileid).with_suffix('.xml'))
        jpeg_file = str(Path(imagedir/fileid).with_suffix(".jpg"))

        tree = etree.parse(anno_file)

        r = {
            "file_name": jpeg_file,
            "image_id": fileid,
            "height": int(tree.findall("./size/height")[0].text),
            "width": int(tree.findall("./size/width")[0].text),
        }
        instances = []

        for obj in tree.findall("object"):
            mclass = obj.find("name").text
            #1. Skip over instances if the instance class is in the 'omit_classes' list,
            #2. Rename those in 'rename_classes' dict, and
            #3. Rename any other classes not recognized to "other_animal"
            if not mclass in omit_classes:
                mclass = maybe_rename_class(mclass,rename_classes)
                if not mclass in CLASS_NAMES:
                    mclass = "other_animal"
                bbox = obj.find("bndbox")
                bbox = [float(bbox.find(x).text) for x in ["xmin", "ymin", "xmax", "ymax"]]
                instances.append(
                    {"category_id": CLASS_NAMES.index(mclass), "bbox": bbox, "bbox_mode": BoxMode.XYXY_ABS}
                )
        r["annotations"] = instances
        dicts.append(r)
    return dicts

# Cell
def evaluate_dicts(model,items):
    """Test-evaluate a list of 1 or more dicts.  Expects one dict per image,
       in Detectron format ({'image':tensor, 'height':int, etc.})
    """
    with inference_context(model), torch.no_grad():
        inputs = items
        if isinstance(items,dict):
            items = [items] #make a single dict into a list
        outputs = model(items)
        return outputs

def evaluate_dataloader_item(dataloader,model,indx):
    """Test-evaluate one item from a dataloader.  The item is expected to be a Pytorch tensor.
    """
    etl = enumerate(dataloader)
    with inference_context(model), torch.no_grad():
        found = False
        for idx, inputs in etl:
            if idx==indx:
                outputs = model(inputs)
                return outputs
        if found == False:
            return "Index not found"

# Cell
def dummy_detectron2_result():
    """Generates a couple of fake bounding box instances in Detectron2 format."""
    dummy_result = Instances((500,500))
    dummyboxes = Boxes([[1,2,3,4],[5,6,7,8]])
    dummy_result.pred_boxes = dummyboxes
    dummy_result.pred_classes = [0,13]
    dummy_result.scores = [0.65,1.877]
    return dummy_result

# Cell
def combine_tile_annotations(tile_results,tile_size,overlap,fullimage_size):
    """Reassemble Detectron2-style annotations for individual tiles into an annotation for the original file.
       Duplication of boxes due to tile overlap is ignored (all boxes are returned, regardless of overlap).

       **Arguments**:
       - `tile_results`: OrderedDict.  Results returned by the model (an OrderedDict with one element called 'Predictions')
       - `tile_size`: int.  tile size in pixels
       - `overlap`: int. tile overlap in pixels
       - `fullimage_size`: tuple.  (height, width) of original image

       Returns: a dict with the combined Instances objects (boxes, scores, predicted classes)
    """
    tile_predictions = tile_results['Predictions']
    firsttile = True
    for tres in tile_predictions:
        trow = tres["trow"]
        tcol = tres["tcol"]
        row_offset,col_offset = get_tile_offsets(trow,tcol,tile_size,overlap) #use regex
        tinst = tres['instances']
        tboxes = tinst.pred_boxes.tensor
        tscores = tinst.scores
        tclasses = tinst.pred_classes
        #Adjust boxes by tile offset
        N = tboxes.shape[0]
        for r in range(N):
            tboxes[r,0] += col_offset
            tboxes[r,2] += col_offset
            tboxes[r,1] += row_offset
            tboxes[r,3] += row_offset
        if firsttile:
            master_boxes = tboxes
            master_scores = tscores
            master_classes = tclasses
            firsttile = False
        else:
            master_boxes = torch.cat((master_boxes, tboxes), 0)
            master_scores = torch.cat((master_scores, tscores), 0)
            master_classes = torch.cat((master_classes, tclasses), 0)
    master_instances = Instances(fullimage_size) #fullimage_size is a tuple (ht,width)
    master_instances.pred_boxes = Boxes(master_boxes.cpu())
    master_instances.scores = master_scores.cpu()
    master_instances.pred_classes = master_classes.cpu()
    return {"instances":master_instances}

# Cell
def save_annotated_image(image, annotations,CLASS_NAMES,outfile):
    """Saves a single annotated image as a jpg file. Returns 0 if successful, 1 if not.
       Parameters:
       image: Numpy array.
       annotations: output of a Detectron2 model (a dict; not the same format as input dict).
       outfile: filename (including path) for the output file
    """
    #test_metadata is required to get label names in the image
    if "test" not in DatasetCatalog.list():
        register_dataset_from_dicts([],"test",CLASS_NAMES)
    test_metadata = MetadataCatalog.get("test")
    try:
        visualizer = Visualizer(image, metadata=test_metadata, scale=1.0)
    except TypeError as err:
        print(err)
        return 1
    else:
        vis = visualizer.draw_instance_predictions(annotations["instances"])
        vis.save(outfile)
        return 0

def save_annotated_images(imagelist,ann_dict,CLASS_NAMES,output_dir,suffix):
    """Takes a list of image names plus a corresponding list of annotations
    in Detectron2 format (i.e, a list of Detectron2-style result dicts),
    overlays the annotations and saves annotated images to file as jpgs.
    Adds '_ann' by default to the filename, but a different suffix can be provided.
    Parameters:
    imagelist: list [str].  List of image filenames (full paths)
    ann_dict: list[dict].  List of dicts in same order as imagelist (Detectron2 output).
    output_dir: str.  Output directory.
    suffix: str. Suffix to be added to the filename of the output file.
    """
    if suffix is None:
        suffix = '_ann'
    assert len(imagelist)==len(ann_dict),"Image list and annotation dict are different lengths."
    n_written = 0
    for i in range(len(imagelist)):
        img_arr = np.array(Image.open(imagelist[i]))
        fstem = Path(imagelist[i]).stem
        ext = Path(imagelist[i]).suffix
        fname = fstem + suffix + ext
        outfile = str(Path(output_dir)/fname)
        annotation = ann_dict[i]
        result = save_annotated_image(img_arr, annotation,CLASS_NAMES,outfile)
        if result == 1:
            print("Annotated image cannot be saved:",fname)
            next
        else:
            n_written += 1
    print (n_written," image files written.")


# Cell
def write_results_to_xml(result_dict,outdir,CLASS_NAMES):
    """
    Writes a dict containing annotations in Detectron2 format to PASCAL-VOC xml-style annotation files,
    one xml file per image file, using the pascal_voc_writer package.
    Also writes a summary csv file with number of instances of each class detected per image.
    Parameters:
    resultdict: a list containing dicts in Detectron2 annotation format
    outdir: str Output directory (files will be written here)
    """
    nfiles = len(result_dict)
    assert nfiles > 0, "Result dict has length zero"
    #Set up a dict for tracking class counts (we'll turn into a dataframe)
    class_counts = {"file_name":np.zeros(nfiles).tolist()}
    for cn in range(len(CLASS_NAMES)):
        class_counts[CLASS_NAMES[cn]] = np.zeros(nfiles).tolist()

    n_written = 0
    for i in range(nfiles):
        #Get contents of the dict
        d = result_dict[i]
        assert 'file_name' in d, "file_name not found in result dict"
        filename = d["file_name"]
        filestem = Path(filename).stem
        assert (('height' in d) and ('width' in d)), "Height and/or width not found in result dict"
        height,width = d["height"], d["width"]
        assert 'instances' in d, "instances not found in result dict"
        instances = d["instances"]
        boxes = instances.pred_boxes.tensor
        scores = instances.scores.tolist()
        classes = instances.pred_classes.tolist()

        #Count the number of occurrences of each class in an incrementing list (for a summary)
        valcount = Counter(classes)
        class_counts["file_name"][i] = filename
        for k,v in valcount.items():
            class_counts[CLASS_NAMES[k]][i] += v

        writer = PascalVocWriter(filename, width, height) # Writer(image_filepath, image_width, image_height)
        #writer.changePath(relpath)
        #writer.changeFolder(folder)

        assert ((boxes.shape[0]==len(scores)) & (len(scores)==len(classes))), 'Lengths of boxes, scores and classes dont match'
        for inst in range(len(scores)):
            xmin, ymin, xmax, ymax = boxes[inst].tolist()
            name = CLASS_NAMES[classes[inst]] #convert integer back to text for classname
            score = scores[inst]
            writer.addObject(name, xmin, ymin, xmax, ymax, score=score, pose='Unspecified', truncated=0, difficult=0)
        outfile = str((Path(outdir)/filestem).with_suffix('.xml'))
        writer.save(outfile)
        n_written +=1
    #Convert to dataframe and write csv file
    ccounts = pd.DataFrame.from_dict(class_counts,'columns')
    ccounts.to_csv(str(Path(outdir)/'class_counts.csv'), sep=',', encoding='utf-8',index=False)
    print("   Created " + str(n_written) + " new annotation files; ")
    return(class_counts)



# Cell
def read_in_predictions(f,CLASS_NAMES):
    anno_file = f
    tree = etree.parse(anno_file)

    fname_tup = tree.find("filename").text,
    height_tup = tree.find("./size/height").text,
    width_tup =  tree.find("./size/width").text,

    #Python won't let me include this in the previous step!
    fname = fname_tup[0]
    height = int(height_tup[0])
    width = int(width_tup[0])

    #Create the output dict
    predictions = {
        "file_name": fname,
        "height": height,
        "width": width
    }
    #Instantiate the Instances object
    size = (height, width)
    instances = Instances(size)
    classes = []
    boxes = []
    scores = []

    for obj in tree.findall("object"):
        class_label = obj.find("name").text
        class_id = CLASS_NAMES.index(class_label)
        bbox = obj.find("bndbox")
        bbox = [float(bbox.find(x).text) for x in ["xmin", "ymin", "xmax", "ymax"]]
        score = obj.find("score")

        classes.append(class_id)
        boxes.append(bbox)
        scores.append(score)

    boxes_array = np.asarray([bx for bx in boxes]).reshape(-1, 4)
    labels_array = torch.tensor(classes)
    if score is None:
        score_array = torch.zeros(len(labels_array))
    else:
        score_array = torch.tensor(scores)

    #Add to the Instances object
    instances.scores = score_array
    instances.pred_boxes = Boxes(boxes_array)
    instances.pred_classes = labels_array

    #Return the dict
    predictions["instances"]= instances
    return predictions